{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "uctUTACKr9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sERtLvU4-fr"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATcaIkuI4I5K",
        "outputId": "89280b3b-206e-430c-c0b7-7c70bfa0765b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-18 17:31:07--  https://repo.continuum.io/miniconda/Miniconda3-py37_4.11.0-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.177.84, 104.18.176.84, 2606:4700::6812:b054, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.177.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-py37_4.11.0-Linux-x86_64.sh [following]\n",
            "--2025-05-18 17:31:07--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.11.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103730670 (99M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.11.0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.1 100%[===================>]  98.92M   126MB/s    in 0.8s    \n",
            "\n",
            "2025-05-18 17:31:08 (126 MB/s) - ‘Miniconda3-py37_4.11.0-Linux-x86_64.sh’ saved [103730670/103730670]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py37h27cfd23_1003\n",
            "    - ca-certificates==2021.10.26=h06a4308_2\n",
            "    - certifi==2021.10.8=py37h06a4308_2\n",
            "    - cffi==1.15.0=py37hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.7.3=py37h27cfd23_1\n",
            "    - conda==4.11.0=py37h06a4308_0\n",
            "    - cryptography==36.0.0=py37h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1m=h7f8727e_0\n",
            "    - pip==21.2.2=py37h06a4308_0\n",
            "    - pycosat==0.6.3=py37h27cfd23_0\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==21.0.0=pyhd3eb1b0_1\n",
            "    - pysocks==1.7.1=py37_1\n",
            "    - python==3.7.11=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py37h27cfd23_0\n",
            "    - setuptools==58.0.4=py37h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_0\n",
            "    - sqlite==3.37.0=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.62.3=pyhd3eb1b0_1\n",
            "    - urllib3==1.26.7=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.11=h7f8727e_4\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py37h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2021.10.26-h06a4308_2\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py37h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py37hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.11.0-py37h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.3-py37h27cfd23_1\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py37h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1m-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py37h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h27cfd23_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-21.0.0-pyhd3eb1b0_1\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_1\n",
            "  python             pkgs/main/linux-64::python-3.7.11-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py37h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py37h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.37.0-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.62.3-pyhd3eb1b0_1\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.7-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7f8727e_4\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-py37_4.11.0-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAZj8UYh4Kpi",
        "outputId": "4303a13a-cada-407f-c134-f58dade73d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.7/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "modified      /root/.bashrc\n",
            "\n",
            "==> For changes to take effect, close and re-open your current shell. <==\n",
            "\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.11.0\n",
            "  latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/retfound\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.7.5\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    ca-certificates-2025.2.25  |       h06a4308_0         129 KB\n",
            "    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n",
            "    libedit-3.1.20230828       |       h5eee18b_0         179 KB\n",
            "    libffi-3.2.1               |    hf484d3e_1007          48 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    ncurses-6.4                |       h6a678d5_0         914 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-22.3.1                 |   py37h06a4308_0         2.7 MB\n",
            "    python-3.7.5               |       h0371630_0        32.2 MB\n",
            "    readline-7.0               |       h7b6447c_5         324 KB\n",
            "    setuptools-65.6.3          |   py37h06a4308_0         1.1 MB\n",
            "    sqlite-3.33.0              |       h62c20be_0         1.1 MB\n",
            "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
            "    wheel-0.38.4               |   py37h06a4308_0          63 KB\n",
            "    xz-5.6.4                   |       h5eee18b_1         567 KB\n",
            "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        57.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0\n",
            "  certifi            pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20230828-h5eee18b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hf484d3e_1007\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-22.3.1-py37h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.7.5-h0371630_0\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  setuptools         pkgs/main/linux-64::setuptools-65.6.3-py37h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.38.4-py37h06a4308_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "readline-7.0         | 324 KB    | : 100% 1.0/1 [00:00<00:00,  3.87it/s]\n",
            "certifi-2022.12.7    | 150 KB    | : 100% 1.0/1 [00:00<00:00,  5.56it/s]\n",
            "ca-certificates-2025 | 129 KB    | : 100% 1.0/1 [00:00<00:00,  5.40it/s]\n",
            "ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:00<00:00,  2.69it/s]\n",
            "wheel-0.38.4         | 63 KB     | : 100% 1.0/1 [00:00<00:00,  5.68it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00,  5.95it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  4.00it/s]\n",
            "python-3.7.5         | 32.2 MB   | : 100% 1.0/1 [00:01<00:00,  1.03s/it]               \n",
            "pip-22.3.1           | 2.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00,  5.26it/s]\n",
            "xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:00<00:00,  4.99it/s]\n",
            "libedit-3.1.20230828 | 179 KB    | : 100% 1.0/1 [00:00<00:00,  4.59it/s]\n",
            "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  5.43it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.34it/s]\n",
            "setuptools-65.6.3    | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.63it/s]\n",
            "libffi-3.2.1         | 48 KB     | : 100% 1.0/1 [00:00<00:00,  5.86it/s]\n",
            "sqlite-3.33.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.15it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.58it/s]               \n",
            "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  3.31it/s]               \n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate retfound\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Python 3.7.5\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.16.2-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline>=0.1\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting tornado>=6.1\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets>=5.1.0\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=17\n",
            "  Downloading pyzmq-26.2.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (863 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.0/864.0 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy>=1.0\n",
            "  Downloading debugpy-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/envs/retfound/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel) (65.6.3)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting jupyter-core>=4.9.2\n",
            "  Downloading jupyter_core-4.12.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.4\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, ptyprocess, pickleshare, backcall, traitlets, tornado, six, pyzmq, pygments, psutil, prompt-toolkit, pexpect, parso, packaging, nest-asyncio, entrypoints, decorator, debugpy, python-dateutil, matplotlib-inline, jupyter-core, jedi, jupyter-client, ipython, ipykernel\n",
            "Successfully installed backcall-0.2.0 debugpy-1.7.0 decorator-5.1.1 entrypoints-0.4 ipykernel-6.16.2 ipython-7.34.0 jedi-0.19.2 jupyter-client-7.4.9 jupyter-core-4.12.0 matplotlib-inline-0.1.6 nest-asyncio-1.6.0 packaging-24.0 parso-0.8.4 pexpect-4.9.0 pickleshare-0.7.5 prompt-toolkit-3.0.48 psutil-7.0.0 ptyprocess-0.7.0 pygments-2.17.2 python-dateutil-2.9.0.post0 pyzmq-26.2.1 six-1.17.0 tornado-6.2 traitlets-5.9.0 wcwidth-0.2.13\n",
            "Installed kernelspec python3 in /root/.local/share/jupyter/kernels/python3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\" # copy conda command to shell\n",
        "source /usr/local/etc/profile.d/conda.sh\n",
        "conda init\n",
        "conda create -n retfound python=3.7.5 -y\n",
        "conda activate retfound\n",
        "python --version\n",
        "pip install ipykernel\n",
        "python -m ipykernel install --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJR3JPPl4SWw"
      },
      "source": [
        "# Clone RetFound Edited and install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before cloning, make sure you have forked this repo: https://github.com/Reyhaneesmailizadeh/RETFound-Edited"
      ],
      "metadata": {
        "id": "NlfJeAo8y0ZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UTuE05v4MPZ",
        "outputId": "aac7856f-16f6-47bf-f2d8-b1ff9e185771"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'RETFound-Edited'...\n",
            "remote: Enumerating objects: 416, done.\u001b[K\n",
            "remote: Counting objects: 100% (254/254), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 416 (delta 239), reused 202 (delta 202), pack-reused 162 (from 2)\u001b[K\n",
            "Receiving objects: 100% (416/416), 503.88 KiB | 8.00 MiB/s, done.\n",
            "Resolving deltas: 100% (260/260), done.\n",
            "Collecting certifi\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: certifi\n",
            "Successfully installed certifi-2025.4.26\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m921.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.5.3.56\n",
            "  Downloading opencv_python-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==8.3.1\n",
            "  Downloading Pillow-8.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.17.3\n",
            "  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycm==3.2\n",
            "  Downloading pycm-3.2-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydicom==2.3.0\n",
            "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image==0.17.2\n",
            "  Downloading scikit_image-0.17.2-cp37-cp37m-manylinux1_x86_64.whl (12.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.9/25.9 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard==2.6.0\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server==0.6.1\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit==1.8.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.2/781.2 kB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.3.2\n",
            "  Downloading timm-0.3.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.62.1\n",
            "  Downloading tqdm-4.62.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/envs/retfound/lib/python3.7/site-packages (from pandas==0.25.3->-r requirement.txt (line 6)) (2.9.0.post0)\n",
            "Collecting pytz>=2017.2\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/envs/retfound/lib/python3.7/site-packages (from protobuf==3.17.3->-r requirement.txt (line 8)) (1.17.0)\n",
            "Collecting art>=1.8\n",
            "  Downloading art-6.5-py3-none-any.whl (610 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.4/610.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio>=2.3.0\n",
            "  Downloading imageio-2.31.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx>=2.0\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/retfound/lib/python3.7/site-packages (from tensorboard==2.6.0->-r requirement.txt (line 14)) (65.6.3)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.21.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.62.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/envs/retfound/lib/python3.7/site-packages (from tensorboard==2.6.0->-r requirement.txt (line 14)) (0.38.4)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting imageio>=2.3.0\n",
            "  Downloading imageio-2.31.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.31.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.30.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.29.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.28.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.28.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.27.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.26.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.26.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.25.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.24.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.23.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.4-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.5-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.18.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.17.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.16.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.14.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.14.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.12.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.11.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.11.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/envs/retfound/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->-r requirement.txt (line 11)) (24.0)\n",
            "Collecting networkx>=2.0\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/retfound/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.6.0->-r requirement.txt (line 14)) (2025.4.26)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting typing-extensions\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pytz, zipp, urllib3, typing-extensions, tqdm, threadpoolctl, tensorboard-data-server, pyparsing, pydicom, pyasn1, protobuf, Pillow, oauthlib, numpy, networkx, MarkupSafe, joblib, idna, grpcio, fonttools, cycler, charset-normalizer, cachetools, art, absl-py, werkzeug, torch, tifffile, scipy, rsa, requests, PyWavelets, pycm, pyasn1-modules, pandas, opencv-python, kiwisolver, importlib-metadata, imageio, torchvision, torchaudio, scikit-learn, requests-oauthlib, matplotlib, markdown, google-auth, timm, scikit-image, google-auth-oauthlib, tensorboard\n",
            "Successfully installed MarkupSafe-2.1.5 Pillow-8.3.1 PyWavelets-1.3.0 absl-py-2.1.0 art-6.5 cachetools-4.2.4 charset-normalizer-3.4.2 cycler-0.11.0 fonttools-4.38.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.62.3 idna-3.10 imageio-2.9.0 importlib-metadata-6.7.0 joblib-1.3.2 kiwisolver-1.4.5 markdown-3.4.4 matplotlib-3.5.3 networkx-2.6.3 numpy-1.21.6 oauthlib-3.2.2 opencv-python-4.5.3.56 pandas-0.25.3 protobuf-3.17.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 pycm-3.2 pydicom-2.3.0 pyparsing-3.1.4 pytz-2025.2 requests-2.31.0 requests-oauthlib-2.0.0 rsa-4.9.1 scikit-image-0.17.2 scikit-learn-0.24.2 scipy-1.5.4 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 threadpoolctl-3.1.0 tifffile-2021.11.2 timm-0.3.2 torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111 tqdm-4.62.1 typing-extensions-4.7.1 urllib3-2.0.7 werkzeug-2.2.3 zipp-3.15.0\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "git clone https://github.com/Reyhaneesmailizadeh/RETFound-Edited/\n",
        "source activate retfound\n",
        "cd RETFound-Edited/\n",
        "pip install --ignore-installed certifi\n",
        "pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gukAzzrP4WkZ"
      },
      "source": [
        "# Download RETFound SSL weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ucbe-B4aoA",
        "outputId": "b6035fc5-0afe-429a-fdd1-8c58ed4a85ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l62zbWUFTlp214SvK6eMwPQZAzcwoeBE\n",
            "From (redirected): https://drive.google.com/uc?id=1l62zbWUFTlp214SvK6eMwPQZAzcwoeBE&confirm=t&uuid=18c8f0c0-ed09-4d49-8f29-646552dfebfe\n",
            "To: /content/RETFound_cfp_weights.pth\n",
            "100% 3.95G/3.95G [00:48<00:00, 81.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "!gdown --id 1l62zbWUFTlp214SvK6eMwPQZAzcwoeBE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rsWwoAF4eln",
        "outputId": "6d044ec0-6493-4d7f-d1b8-d959bedff745"
      },
      "outputs": [
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "mv RETFound_cfp_weights.pth RETFound-Edited/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLE36GVA4she"
      },
      "source": [
        "# ThickFound: Fine-tune the RetFound-Fundus on the 1469 unlabeled thickness maps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "cd RETFound-Edited\n",
        "eval \"$(conda shell.bash hook)\" # copy conda command to shell\n",
        "source activate retfound\n",
        "python -m torch.distributed.launch --nproc_per_node=1 --master_port=48798 main_pretrain.py \\\n",
        "    --batch_size 4 \\\n",
        "    --world_size 1 \\\n",
        "    --epochs 50 \\\n",
        "    --blr 5e-3 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --input_size 224 \\\n",
        "    --output_dir /content/drive/MyDrive/checkpoints/ \\\n",
        "    --finetune ./RETFound_cfp_weights.pth \\\n",
        "    --log_dir /content/drive/MyDrive/logs/ \\\n",
        "    --data_path /content/drive/MyDrive/pretrain_data/"
      ],
      "metadata": {
        "id": "0tm-vZ4rnYQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SLOFound: Fine-tune the RetFound-Fundus on the 203 unlabeled SLO images."
      ],
      "metadata": {
        "id": "86QmwSf3orfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "cd RETFound-Edited\n",
        "eval \"$(conda shell.bash hook)\" # copy conda command to shell\n",
        "source activate retfound\n",
        "python -m torch.distributed.launch --nproc_per_node=1 --master_port=48798 main_pretrain.py \\\n",
        "    --batch_size 4 \\\n",
        "    --world_size 1 \\\n",
        "    --epochs 50 \\\n",
        "    --blr 5e-3 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --input_size 224 \\\n",
        "    --output_dir /content/drive/MyDrive/checkpoints/ \\\n",
        "    --finetune ./RETFound_cfp_weights.pth \\\n",
        "    --log_dir /content/drive/MyDrive/logs/ \\\n",
        "    --data_path /content/drive/MyDrive/slo-pretraining/"
      ],
      "metadata": {
        "id": "D77mxQCko0In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You want to finetune ThickFound or SLOFound on your own unlabeled data?"
      ],
      "metadata": {
        "id": "JSewZky4pFAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add ThickFound to your drive: https://drive.google.com/file/d/1aMaTW5bp4rEtd5BDYkauOQ0bAbgno0Iw/view?usp=sharing"
      ],
      "metadata": {
        "id": "wam4MpN4qJUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "cd RETFound-Edited\n",
        "eval \"$(conda shell.bash hook)\" # copy conda command to shell\n",
        "source activate retfound\n",
        "python -m torch.distributed.launch --nproc_per_node=1 --master_port=48798 main_pretrain.py \\\n",
        "    --batch_size 4 \\\n",
        "    --world_size 1 \\\n",
        "    --epochs 50 \\\n",
        "    --blr 5e-3 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --input_size 224 \\\n",
        "    --output_dir /content/drive/MyDrive/checkpoints/ \\\n",
        "    --finetune /content/drive/MyDrive/ThickFound.pth \\\n",
        "    --log_dir /content/drive/MyDrive/logs/ \\\n",
        "    --data_path /content/drive/MyDrive/path-to-your-data/"
      ],
      "metadata": {
        "id": "R08NKMrwpNeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add SLOFound to your drive: https://drive.google.com/file/d/1-MCvsW4NWEAMoXNe5VAJrGat6z6GlUkV/view?usp=sharing"
      ],
      "metadata": {
        "id": "yXfFKvT2qTtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "%%shell\n",
        "cd RETFound-Edited\n",
        "eval \"$(conda shell.bash hook)\" # copy conda command to shell\n",
        "source activate retfound\n",
        "python -m torch.distributed.launch --nproc_per_node=1 --master_port=48798 main_pretrain.py \\\n",
        "    --batch_size 4 \\\n",
        "    --world_size 1 \\\n",
        "    --epochs 50 \\\n",
        "    --blr 5e-3 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --input_size 224 \\\n",
        "    --output_dir /content/drive/MyDrive/checkpoints/ \\\n",
        "    --finetune /content/drive/MyDrive/SLOFound.pth \\\n",
        "    --log_dir /content/drive/MyDrive/logs/ \\\n",
        "    --data_path /content/drive/MyDrive/path-to-your-data/"
      ],
      "metadata": {
        "id": "UE0ieyJ0pqnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proposed Model: Unfrozen MultiModal Model using ThickFound and SLOFound. The layer decay rate was set to 0.6"
      ],
      "metadata": {
        "id": "vp9MesgjsLqI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_pCZapfQ-E6",
        "outputId": "03089cad-4a0e-4959-d3e4-3559fd541201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing models_vit.py\n"
          ]
        }
      ],
      "source": [
        "#Code from https://github.com/rmaphoh/RETFound_MAE\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "# Partly revised by YZ @UCL&Moorfields\n",
        "# -------------------------------------------------------\n",
        "%%writefile models_vit.py\n",
        "from functools import partial\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm.models.vision_transformer\n",
        "\n",
        "\n",
        "class VisionTransformer(timm.models.vision_transformer.VisionTransformer):\n",
        "    \"\"\" Vision Transformer with support for global average pooling\n",
        "    \"\"\"\n",
        "    def __init__(self, global_pool=False, **kwargs):\n",
        "        super(VisionTransformer, self).__init__(**kwargs)\n",
        "\n",
        "        self.global_pool = global_pool\n",
        "        if self.global_pool:\n",
        "            norm_layer = kwargs['norm_layer']\n",
        "            embed_dim = kwargs['embed_dim']\n",
        "            self.fc_norm = norm_layer(embed_dim)\n",
        "\n",
        "            del self.norm  # remove the original norm\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        if self.global_pool:\n",
        "            x = x[:, 1:, :].mean(dim=1)  # global pool without cls token\n",
        "            outcome = self.fc_norm(x)\n",
        "        else:\n",
        "            x = self.norm(x)\n",
        "            outcome = x[:, 0]\n",
        "\n",
        "        return outcome\n",
        "\n",
        "\n",
        "def vit_large_patch16(**kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JRk4ZCPtJQg",
        "outputId": "dffbf07a-6cfc-4510-edf8-9bb8b3cd8ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 3.8 MB/s \n",
            "\u001b[?25hCollecting safetensors\n",
            "  Downloading safetensors-0.5.3.tar.gz (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 48 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/71/7e/2d5d6ee7b40c0682315367ec7475693d110f512922d582fef1bd4a63adc3/safetensors-0.5.3.tar.gz#sha256=b6b0d6ecacec39a4fdd99cc19f4576f5219ce858e6fd8dbe7609df0b8dc56965 (from https://pypi.org/simple/safetensors/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/local/bin/python /tmp/pip-standalone-pip-ppsvq1u0/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-y2rsrx0j/normal --no-warn-script-location -v --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- puccinialin Check the logs for full command output.\u001b[0m\n",
            "  Downloading safetensors-0.5.2.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f4/4f/2ef9ef1766f8c194b01b67a63a444d2e557c8fe1d82faf3ebd85f370a917/safetensors-0.5.2.tar.gz#sha256=cb4a8d98ba12fa016f4241932b1fc5e702e5143f5374bba0bbcf7ddc1c4cf2b8 (from https://pypi.org/simple/safetensors/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/local/bin/python /tmp/pip-standalone-pip-lmk68fu9/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-dcc6se_h/normal --no-warn-script-location -v --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- puccinialin Check the logs for full command output.\u001b[0m\n",
            "  Downloading safetensors-0.5.1.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 5.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/cd/4b/a45aedf2375cd86314749ad4760545b6e4ec7b306cfa142776daaca6c980/safetensors-0.5.1.tar.gz#sha256=75927919a73b0f34d6943b531d757f724e65797a900d88d8081fe8b4448eadc3 (from https://pypi.org/simple/safetensors/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/local/bin/python /tmp/pip-standalone-pip-8d4y0qr4/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-70c797xn/normal --no-warn-script-location -v --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- puccinialin Check the logs for full command output.\u001b[0m\n",
            "  Downloading safetensors-0.5.0.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/5d/b3/1d9000e9d0470499d124ca63c6908f8092b528b48bd95ba11507e14d9dba/safetensors-0.5.0.tar.gz#sha256=c47b34c549fa1e0c655c4644da31332c61332c732c47c8dd9399347e9aac69d1 (from https://pypi.org/simple/safetensors/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/local/bin/python /tmp/pip-standalone-pip-_8cerf_w/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-tpo9kyww/normal --no-warn-script-location -v --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- puccinialin Check the logs for full command output.\u001b[0m\n",
            "  Downloading safetensors-0.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
            "\u001b[K     |████████████████████████████████| 436 kB 83.7 MB/s \n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n",
            "\u001b[K     |████████████████████████████████| 670 kB 90.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[K     |████████████████████████████████| 268 kB 90.6 MB/s \n",
            "\u001b[?25hCollecting torch>=1.7\n",
            "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 887.5 MB 8.2 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 10 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 88.2 MB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (58.0.4)\n",
            "Collecting importlib-metadata\n",
            "  Using cached importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.7/site-packages (from huggingface-hub->timm) (4.62.3)\n",
            "Collecting packaging>=20.9\n",
            "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 91.4 MB/s \n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.5.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 68.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, zipp, typing-extensions, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, pyyaml, pillow, packaging, numpy, importlib-metadata, fsspec, filelock, torchvision, safetensors, huggingface-hub, timm\n",
            "Successfully installed filelock-3.12.2 fsspec-2023.1.0 huggingface-hub-0.16.4 importlib-metadata-6.7.0 numpy-1.21.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-24.0 pillow-9.5.0 pyyaml-6.0.1 safetensors-0.4.5 timm-0.9.12 torch-1.13.1 torchvision-0.14.1 typing-extensions-4.7.1 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onjv4NAaeqyB",
        "outputId": "e5f4a651-35a0-4c76-af22-6865f966b1d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                  Version\n",
            "------------------------ ----------\n",
            "brotlipy                 0.7.0\n",
            "certifi                  2021.10.8\n",
            "cffi                     1.15.0\n",
            "charset-normalizer       2.0.4\n",
            "conda                    4.11.0\n",
            "conda-content-trust      0+unknown\n",
            "conda-package-handling   1.7.3\n",
            "cryptography             36.0.0\n",
            "filelock                 3.12.2\n",
            "fsspec                   2023.1.0\n",
            "huggingface-hub          0.16.4\n",
            "idna                     3.3\n",
            "importlib-metadata       6.7.0\n",
            "numpy                    1.21.6\n",
            "nvidia-cublas-cu11       11.10.3.66\n",
            "nvidia-cuda-nvrtc-cu11   11.7.99\n",
            "nvidia-cuda-runtime-cu11 11.7.99\n",
            "nvidia-cudnn-cu11        8.5.0.96\n",
            "packaging                24.0\n",
            "Pillow                   9.5.0\n",
            "pip                      21.2.2\n",
            "pycosat                  0.6.3\n",
            "pycparser                2.21\n",
            "pyOpenSSL                21.0.0\n",
            "PySocks                  1.7.1\n",
            "PyYAML                   6.0.1\n",
            "requests                 2.27.1\n",
            "ruamel-yaml-conda        0.15.100\n",
            "safetensors              0.4.5\n",
            "setuptools               58.0.4\n",
            "six                      1.16.0\n",
            "timm                     0.9.12\n",
            "torch                    1.13.1\n",
            "torchvision              0.14.1\n",
            "tqdm                     4.62.3\n",
            "typing_extensions        4.7.1\n",
            "urllib3                  1.26.7\n",
            "wheel                    0.37.1\n",
            "zipp                     3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part of the code of this cell is inspired by https://github.com/rmaphoh/RETFound_MAE/blob/main/latent_feature.ipynb\n",
        "import models_vit\n",
        "\n",
        "\n",
        "def prepare_model(chkpt_dir, arch='vit_large_patch16'):\n",
        "\n",
        "    model = models_vit.__dict__[arch](\n",
        "        img_size=224,\n",
        "        num_classes=2,\n",
        "        drop_path_rate=0,\n",
        "        global_pool=True,\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(chkpt_dir, map_location='cuda')\n",
        "\n",
        "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
        "    return model\n",
        "\n",
        "def define_model_SLO():\n",
        "\n",
        "    vit_encoder = prepare_model('/content/drive/MyDrive/SloFound.pth', 'vit_large_patch16')\n",
        "    for param in vit_encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    feature_dim = vit_encoder.head.in_features\n",
        "    vit_encoder.head = nn.Identity()\n",
        "\n",
        "\n",
        "    return vit_encoder\n",
        "\n",
        "def define_model_TM():\n",
        "\n",
        "    vit_encoder = prepare_model('/content/drive/MyDrive/ThickFound.pth', 'vit_large_patch16')\n",
        "    for param in vit_encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    feature_dim = vit_encoder.head.in_features\n",
        "    vit_encoder.head = nn.Identity()\n",
        "\n",
        "    return vit_encoder\n"
      ],
      "metadata": {
        "id": "Qy9hnZb_vmfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suTlhpG-YPP-",
        "outputId": "c7affd7c-e151-4740-f104-51aeffa1624f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ],
      "source": [
        "# Copy from https://github.com/rmaphoh/RETFound_MAE/blob/main/util/datasets.py\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "# Partly revised by YZ @UCL&Moorfields\n",
        "# --------------------------------------------------------\n",
        "%%writefile dataset.py\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from timm.data import create_transform\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "\n",
        "def build_dataset(is_train):\n",
        "\n",
        "    transform = build_transform(is_train)\n",
        "    root = os.path.join(\"/content/drive/MyDrive/finetune_data_GCIPL_Edited\", is_train)\n",
        "    dataset = datasets.ImageFolder(root, transform=transform)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def build_transform(is_train):\n",
        "    mean = IMAGENET_DEFAULT_MEAN\n",
        "    std = IMAGENET_DEFAULT_STD\n",
        "    # train transform\n",
        "    if is_train=='train':\n",
        "        # this should always dispatch to transforms_imagenet_train\n",
        "        transform = create_transform(\n",
        "            input_size=224,\n",
        "            is_training=True,\n",
        "            color_jitter=None,\n",
        "            auto_augment='rand-m9-mstd0.5-inc1',\n",
        "            interpolation='bicubic',\n",
        "            re_prob=0.25,\n",
        "            re_mode='pixel',\n",
        "            re_count=1,\n",
        "            mean=mean,\n",
        "            std=std,\n",
        "        )\n",
        "        return transform\n",
        "\n",
        "    # eval transform\n",
        "    t = []\n",
        "    if 224 <= 224:\n",
        "        crop_pct = 224 / 256\n",
        "    else:\n",
        "        crop_pct = 1.0\n",
        "    size = int(224 / crop_pct)\n",
        "    t.append(\n",
        "        transforms.Resize(size, interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    )\n",
        "    t.append(transforms.CenterCrop(224))\n",
        "    t.append(transforms.ToTensor())\n",
        "    t.append(transforms.Normalize(mean, std))\n",
        "    return transforms.Compose(t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def best_model():\n",
        "\n",
        "    vit_encoder_TM = define_model_TM()\n",
        "\n",
        "    vit_encoder_SLO = define_model_SLO()\n",
        "\n",
        "\n",
        "    n_layers = 2\n",
        "    layers = []\n",
        "    feature_dim = 1024 * 2\n",
        "    in_features = feature_dim\n",
        "\n",
        "    out_features = 31\n",
        "    layers.append(nn.Linear(in_features, out_features))\n",
        "    layers.append(nn.ReLU())\n",
        "    p = 0.20437990802745362\n",
        "    layers.append(nn.Dropout(p))\n",
        "    in_features = out_features\n",
        "\n",
        "    out_features = 10\n",
        "    layers.append(nn.Linear(in_features, out_features))\n",
        "    layers.append(nn.ReLU())\n",
        "    p = 0.3178900937179511\n",
        "    layers.append(nn.Dropout(p))\n",
        "    in_features = out_features\n",
        "\n",
        "    layers.append(nn.Linear(in_features, CLASSES))\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    classifier = nn.Sequential(*layers).to(DEVICE)\n",
        "\n",
        "    classifier.apply(initialize_weights)\n",
        "\n",
        "\n",
        "    return vit_encoder_TM, vit_encoder_SLO, classifier"
      ],
      "metadata": {
        "id": "7WFgXKfevllP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from dataset import build_dataset\n",
        "# Custom dataset class with handling for left/right eyes\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from skimage.transform import resize\n",
        "from PIL import Image, ImageOps\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import pickle\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "BATCHSIZE = 16\n",
        "CLASSES = 1\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 50\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "        elif val_loss > self.best_score - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter}/{self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_score = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "def initialize_weights(model):\n",
        "    \"\"\"\n",
        "    Initialize weights for the classifier model using Xavier (Glorot) initialization.\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, thickness_dir, slo_data, labels, eye_data, transform):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            thickness_dir: Directory containing thickness map images (with 'ms' and 'health' subfolders).\n",
        "            slo_data: Dictionary of SLO images with patient IDs as keys.\n",
        "            labels: Dictionary of labels with patient IDs as keys.\n",
        "            eye_data: Dictionary where each key is a patient ID and each value is a list\n",
        "                      indicating left eye (False) or right eye (True).\n",
        "            transform: Optional transform to be applied on the images.\n",
        "        \"\"\"\n",
        "        self.thickness_dir = thickness_dir\n",
        "        self.slo_data = slo_data\n",
        "        self.labels = labels\n",
        "        self.eye_data = eye_data\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load thickness files from both \"ms\" and \"health\" subdirectories\n",
        "        self.thickness_files = []\n",
        "        for subfolder in ['ms', 'health']:\n",
        "            subfolder_path = os.path.join(thickness_dir, subfolder)\n",
        "            if os.path.exists(subfolder_path):\n",
        "                self.thickness_files.extend([\n",
        "                    os.path.join(subfolder, f) for f in os.listdir(subfolder_path) if f.endswith('.png')\n",
        "                ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.thickness_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      thickness_filename = self.thickness_files[idx]\n",
        "      thickness_path = os.path.join(self.thickness_dir, thickness_filename)\n",
        "      thickness_img = Image.open(thickness_path)\n",
        "\n",
        "      # Get the ID from the filename\n",
        "      parts = os.path.basename(thickness_filename).split('_')\n",
        "      patient_id = parts[1]  # Only use the filename to match patient ID\n",
        "      Thicknessmap_sp = parts[2]\n",
        "      # Get the eye information from the sp dictionary\n",
        "      eye_info = self.eye_data[patient_id]\n",
        "\n",
        "      # We assume the SLO data has two entries (one for each eye)\n",
        "\n",
        "      if len(eye_info) >= 2:\n",
        "          # Check the thickness map to determine which eye we are working with\n",
        "\n",
        "          if Thicknessmap_sp == eye_info[0]:\n",
        "              slo_array = self.slo_data[patient_id][0]\n",
        "          else:\n",
        "              slo_array = self.slo_data[patient_id][1]\n",
        "      elif len(eye_info) == 1:\n",
        "\n",
        "          slo_array = self.slo_data[patient_id][0]\n",
        "\n",
        "      slo_resized = resize(slo_array, (224, 224), anti_aliasing=True)\n",
        "\n",
        "      slo_img = Image.fromarray(slo_resized).resize((224, 224)).convert('RGB')\n",
        "\n",
        "      # Check if the SLO data corresponds to a left eye and needs flipping\n",
        "      if eye_info[0] == False:\n",
        "\n",
        "          slo_img = ImageOps.mirror(slo_img)\n",
        "\n",
        "\n",
        "      if self.transform:\n",
        "          thickness_img = self.transform(thickness_img)\n",
        "          slo_img = self.transform(slo_img)\n",
        "\n",
        "      label = self.labels[patient_id]\n",
        "\n",
        "      return slo_img, thickness_img, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def get_data_merged():\n",
        "        # Load the SLO data and labels\n",
        "    with open('/content/drive/MyDrive/test_labels_Iran.pkl', 'rb') as f:\n",
        "        test_labels = pickle.load(f)\n",
        "\n",
        "    with open('/content/drive/MyDrive/test_slo_iran.pkl', 'rb') as f:\n",
        "        test_slo = pickle.load(f)\n",
        "\n",
        "    with open('/content/drive/MyDrive/train_labels_Iran.pkl', 'rb') as f:\n",
        "        train_labels = pickle.load(f)\n",
        "\n",
        "    with open('/content/drive/MyDrive/train_slo_iran.pkl', 'rb') as f:\n",
        "        train_slo = pickle.load(f)\n",
        "\n",
        "    with open('/content/drive/MyDrive/train_sp_iran.pkl', 'rb') as f:\n",
        "        train_sp = pickle.load(f)\n",
        "\n",
        "    with open('/content/drive/MyDrive/test_sp_iran.pkl', 'rb') as f:\n",
        "        test_sp = pickle.load(f)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Set up data directories\n",
        "    train_thickness_dir = '/content/drive/MyDrive/finetune_data_GCIPL_Edited/train'\n",
        "    test_thickness_dir = '/content/drive/MyDrive/finetune_data_GCIPL_Edited/test'\n",
        "\n",
        "    # Prepare the training and testing datasets\n",
        "    dataset = MyDataset(train_thickness_dir, train_slo, train_labels, train_sp, transform=transform)\n",
        "    dataset_test = MyDataset(test_thickness_dir, test_slo, test_labels, test_sp, transform=transform)\n",
        "\n",
        "    dataset_train, dataset_val = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
        "    sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
        "    sampler_test = torch.utils.data.RandomSampler(dataset_test)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "            dataset_train, sampler=sampler_train,\n",
        "            batch_size=BATCHSIZE,\n",
        "            num_workers=10,\n",
        "            pin_memory=True,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        dataset_val, sampler=sampler_val,\n",
        "        batch_size=BATCHSIZE,\n",
        "        num_workers=10,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset_test, sampler=sampler_test,\n",
        "        batch_size=BATCHSIZE,\n",
        "        num_workers=10,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "metadata": {
        "id": "rAYoNoxXHYlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP5rF-JOSXJO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import lr_decay as lrd\n",
        "import models_vit\n",
        "\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "\n",
        "class MergedModel_IRAN(nn.Module):\n",
        "    def __init__(self, vit_encoder_TM, vit_encoder_SLO, classifier):\n",
        "        super(MergedModel_IRAN, self).__init__()\n",
        "        self.vit_encoder_TM = vit_encoder_TM\n",
        "        self.vit_encoder_SLO = vit_encoder_SLO\n",
        "        self.classifier = classifier\n",
        "\n",
        "        # Ensure encoders have `blocks` for LRD\n",
        "        if not hasattr(self.vit_encoder_TM, \"blocks\") or not hasattr(self.vit_encoder_SLO, \"blocks\"):\n",
        "            raise AttributeError(\"Both ViT encoders must have a 'blocks' attribute for layer-wise decay.\")\n",
        "\n",
        "    def forward(self, thickness_img, slo_img):\n",
        "        latent_features_TM = self.run_batch_images(thickness_img, self.vit_encoder_TM)\n",
        "        latent_features_SLO = self.run_batch_images(slo_img, self.vit_encoder_SLO)\n",
        "        merged_features = torch.cat((latent_features_SLO, latent_features_TM), dim=-1)\n",
        "        return self.classifier(merged_features)\n",
        "\n",
        "    @staticmethod\n",
        "    def run_batch_images(imgs, model):\n",
        "        model = model.to(DEVICE)\n",
        "        x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n",
        "        latent = model.forward_features(x.float())\n",
        "        return torch.squeeze(latent)\n",
        "\n",
        "    def get_param_groups_lrd(self, weight_decay=1e-5, layer_decay=0.5):\n",
        "        \"\"\"Returns parameter groups for applying layer-wise learning rate decay.\"\"\"\n",
        "\n",
        "\n",
        "        param_groups = []\n",
        "\n",
        "        # Apply LRD to both ViT encoders\n",
        "        param_groups += lrd.param_groups_lrd(self.vit_encoder_TM, weight_decay=weight_decay, layer_decay=layer_decay)\n",
        "        param_groups += lrd.param_groups_lrd(self.vit_encoder_SLO, weight_decay=weight_decay, layer_decay=layer_decay)\n",
        "\n",
        "        # Add classifier parameters (without decay)\n",
        "        classifier_params = {\"params\": list(self.classifier.parameters()), \"weight_decay\": weight_decay}\n",
        "        param_groups.append(classifier_params)\n",
        "\n",
        "        return param_groups\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh0JyVrcz2iP",
        "outputId": "c0d2c090-070e-4b86-8346-b364bb7aea31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-8eaa92c0e856>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(chkpt_dir, map_location='cuda')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.0350 | Train Accuracy: 0.6339 | Train F1 Score: 0.3051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.4958 | Validation Accuracy: 0.8966\n",
            "epoch : 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7957 | Train Accuracy: 0.7321 | Train F1 Score: 0.5588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2388 | Validation Accuracy: 0.9310\n",
            "epoch : 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5950 | Train Accuracy: 0.7857 | Train F1 Score: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3787 | Validation Accuracy: 0.8966\n",
            "EarlyStopping counter: 1/10\n",
            "epoch : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6169 | Train Accuracy: 0.7679 | Train F1 Score: 0.6176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.4142 | Validation Accuracy: 0.7241\n",
            "EarlyStopping counter: 2/10\n",
            "epoch : 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5289 | Train Accuracy: 0.7500 | Train F1 Score: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3482 | Validation Accuracy: 0.8966\n",
            "EarlyStopping counter: 3/10\n",
            "epoch : 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3780 | Train Accuracy: 0.8304 | Train F1 Score: 0.6780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2188 | Validation Accuracy: 0.9655\n",
            "epoch : 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2959 | Train Accuracy: 0.8393 | Train F1 Score: 0.7097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2099 | Validation Accuracy: 0.8966\n",
            "epoch : 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3991 | Train Accuracy: 0.8036 | Train F1 Score: 0.6562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1682 | Validation Accuracy: 0.9655\n",
            "epoch : 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3012 | Train Accuracy: 0.8214 | Train F1 Score: 0.6970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1834 | Validation Accuracy: 0.9655\n",
            "EarlyStopping counter: 1/10\n",
            "epoch : 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3045 | Train Accuracy: 0.8036 | Train F1 Score: 0.6071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1768 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 2/10\n",
            "epoch : 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3023 | Train Accuracy: 0.8304 | Train F1 Score: 0.6780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2022 | Validation Accuracy: 0.8966\n",
            "EarlyStopping counter: 3/10\n",
            "epoch : 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2495 | Train Accuracy: 0.8393 | Train F1 Score: 0.6897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1900 | Validation Accuracy: 0.8966\n",
            "EarlyStopping counter: 4/10\n",
            "epoch : 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3172 | Train Accuracy: 0.7589 | Train F1 Score: 0.5424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1767 | Validation Accuracy: 0.9310\n",
            "EarlyStopping counter: 5/10\n",
            "epoch : 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3053 | Train Accuracy: 0.7679 | Train F1 Score: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1952 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 6/10\n",
            "epoch : 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2521 | Train Accuracy: 0.8571 | Train F1 Score: 0.7500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1159 | Validation Accuracy: 0.9655\n",
            "epoch : 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2385 | Train Accuracy: 0.8929 | Train F1 Score: 0.8378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1055 | Validation Accuracy: 0.9655\n",
            "epoch : 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2343 | Train Accuracy: 0.8929 | Train F1 Score: 0.8500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1076 | Validation Accuracy: 0.9655\n",
            "EarlyStopping counter: 1/10\n",
            "epoch : 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1945 | Train Accuracy: 0.9196 | Train F1 Score: 0.8615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0916 | Validation Accuracy: 1.0000\n",
            "epoch : 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1972 | Train Accuracy: 0.9464 | Train F1 Score: 0.9211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0852 | Validation Accuracy: 0.9655\n",
            "epoch : 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2051 | Train Accuracy: 0.9554 | Train F1 Score: 0.9367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0758 | Validation Accuracy: 1.0000\n",
            "epoch : 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2045 | Train Accuracy: 0.9464 | Train F1 Score: 0.9231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0807 | Validation Accuracy: 0.9655\n",
            "EarlyStopping counter: 1/10\n",
            "epoch : 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1715 | Train Accuracy: 0.9375 | Train F1 Score: 0.9114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0784 | Validation Accuracy: 0.9655\n",
            "EarlyStopping counter: 2/10\n",
            "epoch : 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1236 | Train Accuracy: 0.9732 | Train F1 Score: 0.9577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0658 | Validation Accuracy: 1.0000\n",
            "epoch : 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2033 | Train Accuracy: 0.8929 | Train F1 Score: 0.8605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0584 | Validation Accuracy: 1.0000\n",
            "epoch : 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1418 | Train Accuracy: 0.9821 | Train F1 Score: 0.9722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0584 | Validation Accuracy: 1.0000\n",
            "epoch : 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1212 | Train Accuracy: 0.9554 | Train F1 Score: 0.9351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0617 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 1/10\n",
            "epoch : 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1652 | Train Accuracy: 0.9821 | Train F1 Score: 0.9714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0617 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 2/10\n",
            "epoch : 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1566 | Train Accuracy: 0.9732 | Train F1 Score: 0.9577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0591 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 3/10\n",
            "epoch : 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1642 | Train Accuracy: 0.9554 | Train F1 Score: 0.9351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0592 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 4/10\n",
            "epoch : 29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1437 | Train Accuracy: 0.9643 | Train F1 Score: 0.9474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0574 | Validation Accuracy: 1.0000\n",
            "epoch : 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1584 | Train Accuracy: 0.9464 | Train F1 Score: 0.9231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0538 | Validation Accuracy: 1.0000\n",
            "epoch : 31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1390 | Train Accuracy: 0.9643 | Train F1 Score: 0.9459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0510 | Validation Accuracy: 1.0000\n",
            "epoch : 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1545 | Train Accuracy: 0.9554 | Train F1 Score: 0.9367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0507 | Validation Accuracy: 1.0000\n",
            "epoch : 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1452 | Train Accuracy: 0.9732 | Train F1 Score: 0.9610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0506 | Validation Accuracy: 1.0000\n",
            "epoch : 34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1184 | Train Accuracy: 0.9643 | Train F1 Score: 0.9459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0507 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 1/10\n",
            "epoch : 35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1705 | Train Accuracy: 0.9286 | Train F1 Score: 0.8947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0514 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 2/10\n",
            "epoch : 36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1447 | Train Accuracy: 0.9464 | Train F1 Score: 0.9250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0533 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 3/10\n",
            "epoch : 37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1277 | Train Accuracy: 0.9732 | Train F1 Score: 0.9589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0547 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 4/10\n",
            "epoch : 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0892 | Train Accuracy: 0.9821 | Train F1 Score: 0.9730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0554 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 5/10\n",
            "epoch : 39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1292 | Train Accuracy: 0.9821 | Train F1 Score: 0.9722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0551 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 6/10\n",
            "epoch : 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1398 | Train Accuracy: 0.9464 | Train F1 Score: 0.9250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0547 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 7/10\n",
            "epoch : 41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1108 | Train Accuracy: 0.9821 | Train F1 Score: 0.9714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0543 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 8/10\n",
            "epoch : 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0991 | Train Accuracy: 0.9821 | Train F1 Score: 0.9722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0535 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 9/10\n",
            "epoch : 43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1262 | Train Accuracy: 0.9554 | Train F1 Score: 0.9367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0534 | Validation Accuracy: 1.0000\n",
            "EarlyStopping counter: 10/10\n",
            "Early stopping triggered\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3c610b8abcee>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(imgs).to(DEVICE, non_blocking=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.1343\n",
            "Test Accuracy: 0.9737\n",
            "Test F1 Score: 0.9655\n",
            "Test Precision: 0.9333\n",
            "Test Recall (Sensitivity): 1.0000\n",
            "Test Specificity: 0.9583\n",
            "Test AUC-ROC: 0.9792\n"
          ]
        }
      ],
      "source": [
        "\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "device = torch.device(\"cuda\")\n",
        "BATCHSIZE = 16\n",
        "CLASSES = 1\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 50\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
        "\n",
        "vit_encoder_TM, vit_encoder_SLO, classifier = best_model()\n",
        "\n",
        "merged_model_iran = MergedModel_IRAN(vit_encoder_TM, vit_encoder_SLO, classifier)\n",
        "merged_model_iran.to(DEVICE)\n",
        "\n",
        "\n",
        "param_groups = merged_model_iran.get_param_groups_lrd(weight_decay=1e-5, layer_decay=0.6)\n",
        "\n",
        "lr = 0.011877810264748673\n",
        "\n",
        "optimizer = torch.optim.AdamW(param_groups, lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader, valid_loader, test_loader = get_data_merged()\n",
        "\n",
        "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, min_lr=1e-6, verbose=True)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_train_loss = 0.0\n",
        "    print(f\"epoch : {epoch}\", flush=True)\n",
        "    merged_model_iran.train()\n",
        "    train_targets, train_preds = [], []\n",
        "\n",
        "    for slo_img, thickness_img, target in train_loader:\n",
        "\n",
        "\n",
        "        slo_img, thickness_img, target = slo_img.to(device), thickness_img.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = merged_model_iran(thickness_img, slo_img)\n",
        "\n",
        "        target = target.to(DEVICE)\n",
        "\n",
        "\n",
        "        criterion = nn.BCELoss()\n",
        "        if BATCHSIZE != 1:\n",
        "          output = output.squeeze()\n",
        "        loss = criterion(output, target.float())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted = (output > 0.5).float()\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "        train_preds.extend(predicted.cpu().numpy())\n",
        "        train_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_targets, train_preds)\n",
        "    train_f1 = f1_score(train_targets, train_preds)\n",
        "    epoch_train_loss /= len(train_loader)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    print(f\"Train Loss: {epoch_train_loss:.4f} | Train Accuracy: {train_acc:.4f} | Train F1 Score: {train_f1:.4f}\")\n",
        "\n",
        "\n",
        "    merged_model_iran.eval()\n",
        "\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    vl_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for slo_img, thickness_img, target in valid_loader:\n",
        "\n",
        "            slo_img, thickness_img, target = slo_img.to(device), thickness_img.to(device), target.to(device)\n",
        "\n",
        "            output = merged_model_iran(thickness_img, slo_img)\n",
        "\n",
        "            target = target.to(DEVICE)\n",
        "\n",
        "\n",
        "            if BATCHSIZE != 1:\n",
        "              output = output.squeeze()\n",
        "\n",
        "\n",
        "            vl_loss += criterion(output, target.float()).item()\n",
        "\n",
        "\n",
        "            pred = (output > 0.5).float()\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "            all_predictions.extend(pred.cpu().numpy())\n",
        "\n",
        "    vl_l = vl_loss\n",
        "    vl_loss /= len(valid_loader)\n",
        "    val_losses.append(vl_loss)\n",
        "    val_accuracy = accuracy_score(all_targets, all_predictions)\n",
        "    print(f\"Validation Loss: {vl_loss:.4f} | Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    scheduler.step(val_accuracy)\n",
        "\n",
        "\n",
        "    if early_stopping(vl_l):\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "\n",
        "merged_model_iran.eval()\n",
        "all_targets_t = []\n",
        "all_predictions_t = []\n",
        "\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for slo_img, thickness_img, target in test_loader:\n",
        "        slo_img, thickness_img, target = slo_img.to(device), thickness_img.to(device), target.to(device)\n",
        "\n",
        "        output = merged_model_iran(thickness_img, slo_img)\n",
        "\n",
        "        if BATCHSIZE != 1:\n",
        "            output = output.squeeze()\n",
        "\n",
        "        test_loss += criterion(output, target.float()).item()\n",
        "        pred = (output > 0.5).float()\n",
        "        all_targets_t.extend(target.cpu().numpy())\n",
        "        all_predictions_t.extend(pred.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "\n",
        "accuracy_t = accuracy_score(all_targets_t, all_predictions_t)\n",
        "f1 = f1_score(all_targets_t, all_predictions_t)\n",
        "precision = precision_score(all_targets_t, all_predictions_t)\n",
        "recall = recall_score(all_targets_t, all_predictions_t)\n",
        "auc_roc = roc_auc_score(all_targets_t, all_predictions_t)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(all_targets_t, all_predictions_t).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy_t:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"Test Specificity: {specificity:.4f}\")\n",
        "print(f\"Test AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "\n",
        "torch.save(classifier.state_dict(), 'classifier_weights_unfreezed_2layers.pth')\n",
        "torch.save(merged_model_iran.vit_encoder_TM.state_dict(), 'vit_encoder_TM_unfreezed_2layers.pth')\n",
        "torch.save(merged_model_iran.vit_encoder_SLO.state_dict(), 'vit_encoder_SLO_unfreezed_2layers.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0XhTOSoa3Zdx",
        "outputId": "298a5e2e-7f04-4849-ebd5-fc284097d472"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range(len(train_losses)), train_losses, label='Train Loss')\n",
        "plt.plot(range(len(val_losses)), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    }
  ]
}